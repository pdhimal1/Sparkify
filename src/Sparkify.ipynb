{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Prakash Dhimal\n",
    "Manav Garkel\n",
    "George Mason University\n",
    "CS 657 Mining Massive Datasets\n",
    "Final Project: Sparkify\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customer Churn prediction\n",
    "The goal of this project is to build a customer churn prediction model using user interaction logs with an imaginary music streaming service called Sparkify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "Sparkify is imaginary digital music service similar to Spotify. The dataset contains 12GB of user interactions with this fictitious music streaming service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides step by step explanation of our work leading to customer churn prediction using four different models (plus a hybrid model). Let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://pdsager:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sparkify</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f286d8a0ef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"sparkify\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.json(\"../../../data/sparkify_event_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data, we will do a vertical show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | Popol Vuh            \n",
      " auth          | Logged In            \n",
      " firstName     | Shlok                \n",
      " gender        | M                    \n",
      " itemInSession | 278                  \n",
      " lastName      | Johnson              \n",
      " length        | 524.32934            \n",
      " level         | paid                 \n",
      " location      | Dallas-Fort Worth... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1533734541000        \n",
      " sessionId     | 22683                \n",
      " song          | Ich mache einen S... \n",
      " status        | 200                  \n",
      " ts            | 1538352001000        \n",
      " userAgent     | \"Mozilla/5.0 (Win... \n",
      " userId        | 1749042              \n",
      "-RECORD 1-----------------------------\n",
      " artist        | Los Bunkers          \n",
      " auth          | Logged In            \n",
      " firstName     | Vianney              \n",
      " gender        | F                    \n",
      " itemInSession | 9                    \n",
      " lastName      | Miller               \n",
      " length        | 238.39302            \n",
      " level         | paid                 \n",
      " location      | San Francisco-Oak... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1537500318000        \n",
      " sessionId     | 20836                \n",
      " song          | MiÃÂ©ntele          \n",
      " status        | 200                  \n",
      " ts            | 1538352002000        \n",
      " userAgent     | \"Mozilla/5.0 (Mac... \n",
      " userId        | 1563081              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important column in the data set seems to be the `Page` column. It holds all Sparkify pages that the customers have visited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|page                     |\n",
      "+-------------------------+\n",
      "|Cancel                   |\n",
      "|Submit Downgrade         |\n",
      "|Thumbs Down              |\n",
      "|Home                     |\n",
      "|Downgrade                |\n",
      "|Roll Advert              |\n",
      "|Logout                   |\n",
      "|Save Settings            |\n",
      "|Cancellation Confirmation|\n",
      "|About                    |\n",
      "|Submit Registration      |\n",
      "|Settings                 |\n",
      "|Login                    |\n",
      "|Register                 |\n",
      "|Add to Playlist          |\n",
      "|Add Friend               |\n",
      "|NextSong                 |\n",
      "|Thumbs Up                |\n",
      "|Help                     |\n",
      "|Upgrade                  |\n",
      "+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"page\").dropDuplicates().show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list above we can use the `Cancellation Confirmation` to indicate if a particular user churned or not. We are building a model that predicts if a user is going to churn given the history of interactions with the service.\n",
    "\n",
    "Therfore, it is important to understand the customers that reached the `Cancellation Confirmation` page. These are the customers that churned, and the task is to build a prediction model that can recognize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we indentified our \"goal\", we can let go of some of the columns that are not needed for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | Popol Vuh            \n",
      " auth          | Logged In            \n",
      " gender        | M                    \n",
      " itemInSession | 278                  \n",
      " length        | 524.32934            \n",
      " level         | paid                 \n",
      " location      | Dallas-Fort Worth... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1533734541000        \n",
      " sessionId     | 22683                \n",
      " song          | Ich mache einen S... \n",
      " status        | 200                  \n",
      " ts            | 1538352001000        \n",
      " userAgent     | \"Mozilla/5.0 (Win... \n",
      " userId        | 1749042              \n",
      "-RECORD 1-----------------------------\n",
      " artist        | Los Bunkers          \n",
      " auth          | Logged In            \n",
      " gender        | F                    \n",
      " itemInSession | 9                    \n",
      " length        | 238.39302            \n",
      " level         | paid                 \n",
      " location      | San Francisco-Oak... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1537500318000        \n",
      " sessionId     | 20836                \n",
      " song          | MiÃÂ©ntele          \n",
      " status        | 200                  \n",
      " ts            | 1538352002000        \n",
      " userAgent     | \"Mozilla/5.0 (Mac... \n",
      " userId        | 1563081              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(*['firstName', 'lastName', 'id_copy'])\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are building a model that focuses on a user, remove any null/na values in the userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter((isnan(data['userId'])) | (data['userId'].isNull()) | (data['userId'] == \"\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter((data['userId'] == \"\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.filter(data[\"userId\"] != \"\") \n",
    "data.filter((isnan(data['userId'])) | (data['userId'].isNull()) | (data['userId'] == \"\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times in `registration` and `ts` column are given in milliseconds, we will convert those to seconds. Before that, we will remove any with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data['registration'].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "| registration|           ts|\n",
      "+-------------+-------------+\n",
      "|1.533734541E9|1.538352001E9|\n",
      "|1.537500318E9|1.538352002E9|\n",
      "|1.536414505E9|1.538352002E9|\n",
      "| 1.53438666E9|1.538352003E9|\n",
      "|1.537381415E9|1.538352003E9|\n",
      "| 1.53760256E9|1.538352004E9|\n",
      "|1.536563853E9|1.538352005E9|\n",
      "|1.538069376E9|1.538352006E9|\n",
      "|1.536455539E9|1.538352006E9|\n",
      "|1.533220062E9|1.538352006E9|\n",
      "|1.534393835E9|1.538352006E9|\n",
      "|1.537618545E9|1.538352006E9|\n",
      "|1.537868758E9|1.538352007E9|\n",
      "|1.534635513E9|1.538352007E9|\n",
      "|1.531817572E9|1.538352008E9|\n",
      "|1.528964849E9|1.538352008E9|\n",
      "| 1.53676124E9|1.538352008E9|\n",
      "|1.537790336E9|1.538352008E9|\n",
      "| 1.53421749E9| 1.53835201E9|\n",
      "|1.536693084E9| 1.53835201E9|\n",
      "+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_unit_udf = F.udf(lambda x: float(x/1000), DoubleType())\n",
    "data = data.withColumn(\"registration\", time_unit_udf(\"registration\")). \\\n",
    "    withColumn(\"ts\", time_unit_udf(\"ts\"))\n",
    "\n",
    "data.select('registration', 'ts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above we are deriving the label `churn` as a function of the `Page` column. There are only two values to churn, churned or not churned. Therefore this is going to be a boolean column represented by 1 for churned and 0 for not churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|               churn|\n",
      "+-------+--------------------+\n",
      "|  count|                1223|\n",
      "|   mean|8.176614881439084E-4|\n",
      "| stddev| 0.02859478078502978|\n",
      "|    min|                   0|\n",
      "|    max|                   1|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cancelation_event_udf = F.udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n",
    "data = data.withColumn(\"churn\", cancelation_event_udf(\"page\"))\n",
    "data.filter(data['userId'] == 1749042).describe('churn').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that a particular user will have multiple entries, since this is a database of user activities log. A user may have visitied number of other pages before reaching the \"Cancellation\" page. For a user that has churned, we want to make sure that all of his/her logs record 1 for the churn column. For this we will use the Window function from `sql.window`.\n",
    "\n",
    "For example, user `1749042` above has entries labeled as both churned (1) and not churned (0). We need to make sure that all of his/her entries are labeled as churned. It only takes that one \"Cancellation Confirmation\" to make a user churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum as Fsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"userId\") \\\n",
    "        .rangeBetween(Window.unboundedPreceding,\n",
    "                      Window.unboundedFollowing)\n",
    "data = data.withColumn(\"churn\", Fsum(\"churn\").over(window))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|summary|churn|\n",
      "+-------+-----+\n",
      "|  count| 1223|\n",
      "|   mean|  1.0|\n",
      "| stddev|  0.0|\n",
      "|    min|    1|\n",
      "|    max|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data['userId'] == 1749042).describe('churn').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique users we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22277"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"userID\").dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total churn instances, again a user has multiple entries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5382467"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data['churn'] == 1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a label dataframe that has one entry per each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| userId|label|\n",
      "+-------+-----+\n",
      "|1000280|    1|\n",
      "|1002185|    0|\n",
      "|1017805|    0|\n",
      "|1030587|    0|\n",
      "|1033297|    0|\n",
      "|1057724|    0|\n",
      "|1059049|    0|\n",
      "|1069552|    0|\n",
      "|1071308|    1|\n",
      "|1076191|    1|\n",
      "|1083324|    0|\n",
      "|1102913|    0|\n",
      "|1114507|    0|\n",
      "|1133196|    0|\n",
      "|1142513|    0|\n",
      "|1151194|    0|\n",
      "|1156065|    1|\n",
      "|1178731|    0|\n",
      "|1180406|    0|\n",
      "|1190352|    0|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = data \\\n",
    "    .select('userId', col('churn').alias('label')) \\\n",
    "    .dropDuplicates()\n",
    "label.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users that have been using the service tend to stay with the service, even as a paying customer, than those that recently signed up.\n",
    "\n",
    "Every company selling products and services to customers have an idea of a \"lifetime value\" of a customer. With that in mind we create our first feature.\n",
    "\n",
    "We converted the times to seconds above. After gaining the lifetime of a user, we convert that to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as Fsum, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_since_registration = data \\\n",
    "    .select('userId', 'registration', 'ts') \\\n",
    "    .withColumn('lifetime', (data.ts - data.registration)) \\\n",
    "    .groupBy('userId') \\\n",
    "    .agg({'lifetime': 'max'}) \\\n",
    "    .withColumnRenamed('max(lifetime)', 'lifetime') \\\n",
    "    .select('userId', (col('lifetime') / 3600 / 24).alias('lifetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|           lifetime|\n",
      "+-------+-------------------+\n",
      "|  count|              22277|\n",
      "|   mean|  83.38872055383476|\n",
      "| stddev|  40.88235193199312|\n",
      "|    min|-19.427465277777777|\n",
      "|    max| 410.25917824074077|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_since_registration.describe('lifetime').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bussiness big and small not only rely on their customers coming back for more good and services, but also referring the bussiness to their friends and family. It is in our nature to refer things that we like. With this idea in mind we will create another feature.\n",
    "\n",
    "Again we will user the \"Page\" column specifically looking for the `Add Friend` page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "referring_friends = data \\\n",
    "    .select('userID', 'page') \\\n",
    "    .where(data.page == 'Add Friend') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'add_friend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       add_friend|\n",
      "+-------+-----------------+\n",
      "|  count|            20305|\n",
      "|   mean|18.79655257325782|\n",
      "| stddev|20.74770411629507|\n",
      "|    min|                1|\n",
      "|    max|              222|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "referring_friends.describe('add_friend').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more songs a user listens to, the more likely they are to enjoy the streaming service and keep their subscription. Thus we add a `total_songs_listened` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total songs listened\n",
    "total_songs_listened = data \\\n",
    "    .select('userID', 'song') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'total_songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|       total_songs|\n",
      "+-------+------------------+\n",
      "|  count|             22277|\n",
      "|   mean|1143.8129011985457|\n",
      "| stddev|1321.2139656987083|\n",
      "|    min|                 1|\n",
      "|    max|             13591|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_songs_listened.describe('total_songs').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more songs a user liked on the streaming service, the more it potentially implies that they enjoy their subscription\n",
    "and the value they get from it. They are more likely to keep their subscription if they are liking more songs. Thus we create a feature to count the number of songs a user gives a thumbs_up to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumbs up\n",
    "thumbs_up = data \\\n",
    "    .select('userID', 'page') \\\n",
    "    .where(data.page == 'Thumbs Up') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'num_thumb_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      num_thumb_up|\n",
      "+-------+------------------+\n",
      "|  count|             21732|\n",
      "|   mean|52.984769004233385|\n",
      "| stddev| 64.86699983998629|\n",
      "|    min|                 1|\n",
      "|    max|               836|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thumbs_up.describe('num_thumb_up').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the more songs a user dislikes, the less likely they are to enjoy their subscription and cancel it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumbs down\n",
    "thumbs_down = data \\\n",
    "    .select('userID', 'page') \\\n",
    "    .where(data.page == 'Thumbs Down') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'num_thumb_down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    num_thumb_down|\n",
      "+-------+------------------+\n",
      "|  count|             20031|\n",
      "|   mean|11.942089760870651|\n",
      "| stddev| 12.75272884784001|\n",
      "|    min|                 1|\n",
      "|    max|               154|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thumbs_down.describe('num_thumb_down').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playlist length counts the number of times a user visited the add to playlist page indicating that they added a song to their playlist. A long playlist implies a user is enjoying several songs and wants frequent access to them. This would likely lead to them keeping their subscription. Thus, we create a feature to compute the lenght of the playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_length = data.select('userID', 'page') \\\n",
    "    .where(data.page == 'Add to Playlist') \\\n",
    "    .groupby('userID').count() \\\n",
    "    .withColumnRenamed('count', 'playlist_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|  playlist_length|\n",
      "+-------+-----------------+\n",
      "|  count|            21260|\n",
      "|   mean|28.12422389463782|\n",
      "| stddev|32.27499039023109|\n",
      "|    min|                1|\n",
      "|    max|              340|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "playlist_length.describe('playlist_length').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg songs per session allows us to measure how long each user session lasts when they open the application and start a session. The longer the session, the more songs the user is listening too. This could imply that the user is enjoying the application and is less likely to cancel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_songs_played = data.where('page == \"NextSong\"') \\\n",
    "    .groupby(['userId', 'sessionId']) \\\n",
    "    .count() \\\n",
    "    .groupby(['userId']) \\\n",
    "    .agg({'count': 'avg'}) \\\n",
    "    .withColumnRenamed('avg(count)', 'avg_songs_played')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| avg_songs_played|\n",
      "+-------+-----------------+\n",
      "|  count|            22261|\n",
      "|   mean|67.28930119633605|\n",
      "| stddev|42.00146132153543|\n",
      "|    min|              1.0|\n",
      "|    max|            579.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_songs_played.describe('avg_songs_played').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artist count measures the amount of different artists the user listens to. A user listening to a wide variety of artists could potentially be enjoying the music application more and is likely to keep their subscription. On the other hand, a user listening to only a handful of artists may not be happy with the current subscription and would be likely to churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_count = data \\\n",
    "    .filter(data.page == \"NextSong\") \\\n",
    "    .select(\"userId\", \"artist\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"artist_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     artist_count|\n",
      "+-------+-----------------+\n",
      "|  count|            22261|\n",
      "|   mean|645.0307263824626|\n",
      "| stddev|602.2479741901458|\n",
      "|    min|                1|\n",
      "|    max|             4368|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_count.describe('artist_count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of sessions computes how many times the user has started a session on the app. The more sessions implies more visits to the application meaning they are less likely to churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sessions = data \\\n",
    "    .select(\"userId\", \"sessionId\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'num_sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      num_sessions|\n",
      "+-------+------------------+\n",
      "|  count|             22277|\n",
      "|   mean|13.334964312968532|\n",
      "| stddev|13.027024992429286|\n",
      "|    min|                 1|\n",
      "|    max|               147|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_sessions.describe('num_sessions').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our features, we will join them to create a table of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"lifetime\",\n",
    "        \"total_songs\",\n",
    "        \"num_thumb_up\",\n",
    "        'num_thumb_down',\n",
    "        'add_friend',\n",
    "        'playlist_length',\n",
    "        'avg_songs_played',\n",
    "        'artist_count',\n",
    "        'num_sessions']\n",
    "features = [time_since_registration,\n",
    "            total_songs_listened,\n",
    "            thumbs_up,\n",
    "            thumbs_down,\n",
    "            referring_friends,\n",
    "            playlist_length,\n",
    "            avg_songs_played,\n",
    "            artist_count,\n",
    "            num_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------\n",
      " userId           | 1000280            \n",
      " num_sessions     | 22                 \n",
      " artist_count     | 767                \n",
      " avg_songs_played | 48.666666666666664 \n",
      " playlist_length  | 25                 \n",
      " add_friend       | 14                 \n",
      " num_thumb_down   | 33                 \n",
      " num_thumb_up     | 53                 \n",
      " total_songs      | 1317               \n",
      " lifetime         | 77.30377314814815  \n",
      " label            | 1                  \n",
      "-RECORD 1------------------------------\n",
      " userId           | 1002185            \n",
      " num_sessions     | 17                 \n",
      " artist_count     | 1205               \n",
      " avg_songs_played | 104.58823529411765 \n",
      " playlist_length  | 49                 \n",
      " add_friend       | 25                 \n",
      " num_thumb_down   | 14                 \n",
      " num_thumb_up     | 92                 \n",
      " total_songs      | 2080               \n",
      " lifetime         | 65.75105324074075  \n",
      " label            | 0                  \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = features.pop()\n",
    "while len(features) > 0:\n",
    "    data = data.join(features.pop(), 'userID', 'outer')\n",
    "\n",
    "data = data.join(label, 'userID', 'outer').fillna(0)\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>artist_count</th>\n",
       "      <th>avg_songs_played</th>\n",
       "      <th>playlist_length</th>\n",
       "      <th>add_friend</th>\n",
       "      <th>num_thumb_down</th>\n",
       "      <th>num_thumb_up</th>\n",
       "      <th>total_songs</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000280</td>\n",
       "      <td>22</td>\n",
       "      <td>767</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>1317</td>\n",
       "      <td>77.303773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002185</td>\n",
       "      <td>17</td>\n",
       "      <td>1205</td>\n",
       "      <td>104.588235</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>92</td>\n",
       "      <td>2080</td>\n",
       "      <td>65.751053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1017805</td>\n",
       "      <td>3</td>\n",
       "      <td>223</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>320</td>\n",
       "      <td>54.266389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030587</td>\n",
       "      <td>11</td>\n",
       "      <td>1071</td>\n",
       "      <td>163.555556</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>66</td>\n",
       "      <td>1752</td>\n",
       "      <td>131.597523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1033297</td>\n",
       "      <td>5</td>\n",
       "      <td>215</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>116.144549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1057724</td>\n",
       "      <td>40</td>\n",
       "      <td>2157</td>\n",
       "      <td>98.641026</td>\n",
       "      <td>135</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "      <td>200</td>\n",
       "      <td>4669</td>\n",
       "      <td>96.044549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1059049</td>\n",
       "      <td>5</td>\n",
       "      <td>454</td>\n",
       "      <td>186.333333</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>662</td>\n",
       "      <td>133.714074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1069552</td>\n",
       "      <td>12</td>\n",
       "      <td>389</td>\n",
       "      <td>37.916667</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>582</td>\n",
       "      <td>126.268843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1071308</td>\n",
       "      <td>18</td>\n",
       "      <td>1007</td>\n",
       "      <td>82.882353</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>1693</td>\n",
       "      <td>63.393692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1076191</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>28.905035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  num_sessions  artist_count  avg_songs_played  playlist_length  \\\n",
       "0  1000280            22           767         48.666667               25   \n",
       "1  1002185            17          1205        104.588235               49   \n",
       "2  1017805             3           223         83.333333                5   \n",
       "3  1030587            11          1071        163.555556               46   \n",
       "4  1033297             5           215         47.200000                7   \n",
       "5  1057724            40          2157         98.641026              135   \n",
       "6  1059049             5           454        186.333333               16   \n",
       "7  1069552            12           389         37.916667               11   \n",
       "8  1071308            18          1007         82.882353               26   \n",
       "9  1076191             3            47         15.666667                1   \n",
       "\n",
       "   add_friend  num_thumb_down  num_thumb_up  total_songs    lifetime  label  \n",
       "0          14              33            53         1317   77.303773      1  \n",
       "1          25              14            92         2080   65.751053      0  \n",
       "2          13               4             7          320   54.266389      0  \n",
       "3          23              16            66         1752  131.597523      0  \n",
       "4           4               3            10          299  116.144549      0  \n",
       "5          76              29           200         4669   96.044549      0  \n",
       "6          10               6            29          662  133.714074      0  \n",
       "7           7               6            26          582  126.268843      0  \n",
       "8          31              12            74         1693   63.393692      1  \n",
       "9           0               1             4           64   28.905035      1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- num_sessions: long (nullable = true)\n",
      " |-- artist_count: long (nullable = true)\n",
      " |-- avg_songs_played: double (nullable = false)\n",
      " |-- playlist_length: long (nullable = true)\n",
      " |-- add_friend: long (nullable = true)\n",
      " |-- num_thumb_down: long (nullable = true)\n",
      " |-- num_thumb_up: long (nullable = true)\n",
      " |-- total_songs: long (nullable = true)\n",
      " |-- lifetime: double (nullable = false)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|17274|\n",
      "|    1| 5003|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Assembler and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few more steps before we can feed the data into a model. First we will use a vector assempler to create a feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector assembler\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"unScaled_features\")\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need all of the feature columns before, we will select a few that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " userID            | 1000280              \n",
      " unScaled_features | [77.3037731481481... \n",
      " label             | 1                    \n",
      "-RECORD 1---------------------------------\n",
      " userID            | 1002185              \n",
      " unScaled_features | [65.7510532407407... \n",
      " label             | 0                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.select('userID', 'unScaled_features', 'label')\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have been paying attention to the min and max values output after our features above, they are everywhere. We need to use a scaler to scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " userID            | 1000280              \n",
      " unScaled_features | [77.3037731481481... \n",
      " label             | 1                    \n",
      " features          | [1.89088370641545... \n",
      "-RECORD 1---------------------------------\n",
      " userID            | 1002185              \n",
      " unScaled_features | [65.7510532407407... \n",
      " label             | 0                    \n",
      " features          | [1.60829918371908... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scale the features\n",
    "scaler = StandardScaler(inputCol=\"unScaled_features\", outputCol=\"features\", withStd=True)\n",
    "scalerModel = scaler.fit(data)\n",
    "data = scalerModel.transform(data)\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The split\n",
    "\n",
    "Now that we have our data ready to be transformed and fitted by the models, we split them into training and test set. We will do a 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "trainTest = data.randomSplit([0.8, 0.2])\n",
    "trainingDF = trainTest[0]\n",
    "testDF = trainTest[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Four different models were picked: \n",
    "  * Gradient Boosting Trees, \n",
    "  * Logistic Regression,\n",
    "  * Linear SVC,\n",
    "  * RandomForestClassifier\n",
    "  \n",
    "We used Accuracy and f1-score as for evaluating our models. We are really looking for the highest f1 score. Results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier, LogisticRegression, LinearSVC, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Tree.\n",
    "\n",
    "(Note: we run all of our models through cross validation for our actual predictions, we will defer that to the source code at `../src/sparkify.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "| userID|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|1057724|    0|       0.0|\n",
      "|1059049|    0|       0.0|\n",
      "|1133196|    0|       0.0|\n",
      "|1151194|    0|       0.0|\n",
      "|1156065|    1|       0.0|\n",
      "|1311711|    1|       1.0|\n",
      "|1396378|    1|       0.0|\n",
      "|1507765|    0|       0.0|\n",
      "|1519090|    0|       0.0|\n",
      "|1528396|    1|       1.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Gradient Boosted Trees Metrics:\n",
      "Accuracy: 0.83\n",
      "F1 Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# initialize classifier\n",
    "GradBoostTree = GBTClassifier()\n",
    "\n",
    "# Fit the model\n",
    "cvModel_GradBoostTree = GradBoostTree.fit(trainingDF)\n",
    "\n",
    "# Make Predictions\n",
    "results_GradBoostTree = cvModel_GradBoostTree.transform(testDF)\n",
    "results_GradBoostTree = results_GradBoostTree.select('userID', 'label', 'prediction')\n",
    "results_GradBoostTree.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_GradBoostTree, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_GradBoostTree, {evaluator.metricName: \"f1\"})\n",
    "print('Gradient Boosted Trees Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "| userID|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|1057724|    0|       0.0|\n",
      "|1059049|    0|       0.0|\n",
      "|1133196|    0|       0.0|\n",
      "|1151194|    0|       0.0|\n",
      "|1156065|    1|       0.0|\n",
      "|1311711|    1|       0.0|\n",
      "|1396378|    1|       0.0|\n",
      "|1507765|    0|       0.0|\n",
      "|1519090|    0|       0.0|\n",
      "|1528396|    1|       1.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.78\n",
      "F1 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# initialize classifier\n",
    "lgr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "cvModel_lgr = lgr.fit(trainingDF)\n",
    "\n",
    "# Make Predictions\n",
    "results_lgr = cvModel_lgr.transform(testDF).select('userID', 'label', 'prediction')\n",
    "results_lgr.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_lgr, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_lgr, {evaluator.metricName: \"f1\"})\n",
    "print('Logistic Regression Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "| userID|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|1057724|    0|       0.0|\n",
      "|1059049|    0|       0.0|\n",
      "|1133196|    0|       0.0|\n",
      "|1151194|    0|       0.0|\n",
      "|1156065|    1|       0.0|\n",
      "|1311711|    1|       0.0|\n",
      "|1396378|    1|       0.0|\n",
      "|1507765|    0|       0.0|\n",
      "|1519090|    0|       0.0|\n",
      "|1528396|    1|       0.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Support Vector Machine Metrics:\n",
      "Accuracy: 0.77\n",
      "F1 Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# initialize classifier\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Fit the model\n",
    "cvModel_svc = svc.fit(trainingDF)\n",
    "\n",
    "# Make Predictions\n",
    "results_svc = cvModel_svc.transform(testDF).select('userID', 'label', 'prediction')\n",
    "results_svc.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_svc, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_svc, {evaluator.metricName: \"f1\"})\n",
    "print('Support Vector Machine Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "| userID|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|1057724|    0|       0.0|\n",
      "|1059049|    0|       0.0|\n",
      "|1133196|    0|       0.0|\n",
      "|1151194|    0|       0.0|\n",
      "|1156065|    1|       0.0|\n",
      "|1311711|    1|       0.0|\n",
      "|1396378|    1|       0.0|\n",
      "|1507765|    0|       0.0|\n",
      "|1519090|    0|       0.0|\n",
      "|1528396|    1|       1.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.83\n",
      "F1 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "cvModel_rf= rf_classifier.fit(trainingDF)\n",
    "\n",
    "# Make Predictions\n",
    "results_rf = cvModel_rf.transform(testDF).select('userID', 'label', 'prediction')\n",
    "results_rf.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_rf, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_rf, {evaluator.metricName: \"f1\"})\n",
    "print('Random Forest Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the four models above, Gradient Boosted Trees and Random Forest Classifier came out on top with:\n",
    "  * Accuracy: 0.83\n",
    "  * F1 Score: 0.81 and 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid model\n",
    "\n",
    "Ensemble models sometimes produce great results. We shall create a hybrid model to combine our four models above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets combine the results first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------+--------------+--------------+-------------+\n",
      "| userID|label|prediction_GBT|prediction_LGR|prediction_SVC|prediction_RF|\n",
      "+-------+-----+--------------+--------------+--------------+-------------+\n",
      "|1057724|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1059049|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1133196|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1151194|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1156065|    1|           0.0|           0.0|           0.0|          0.0|\n",
      "|1311711|    1|           1.0|           0.0|           0.0|          0.0|\n",
      "|1396378|    1|           0.0|           0.0|           0.0|          0.0|\n",
      "|1507765|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1519090|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1528396|    1|           1.0|           1.0|           0.0|          1.0|\n",
      "|1537210|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1567623|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1612069|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1617595|    1|           0.0|           0.0|           0.0|          0.0|\n",
      "|1624220|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1627009|    1|           1.0|           1.0|           0.0|          1.0|\n",
      "|1633577|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1770964|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1782257|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "|1796854|    0|           0.0|           0.0|           0.0|          0.0|\n",
      "+-------+-----+--------------+--------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_GradBoostTree = results_GradBoostTree.withColumnRenamed(\"prediction\", \"prediction_GBT\")\n",
    "results_lgr = results_lgr.select('userId', 'prediction').withColumnRenamed(\"prediction\", \"prediction_LGR\")\n",
    "results_svc = results_svc.select('userId', 'prediction').withColumnRenamed(\"prediction\", \"prediction_SVC\")\n",
    "results_rf = results_rf.select('userId', 'prediction').withColumnRenamed(\"prediction\", \"prediction_RF\")\n",
    "results = results_GradBoostTree.join(results_lgr, 'userID', 'outer')\n",
    "results = results.join(results_svc, 'userID', 'outer').join(results_rf, 'userID', 'outer')\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hybrid model will simply be an OR function. This means that if a model has labelled if a user will churn, the hybrid model will label that user as churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------+--------------+--------------+-------------+----------+\n",
      "| userID|label|prediction_GBT|prediction_LGR|prediction_SVC|prediction_RF|prediction|\n",
      "+-------+-----+--------------+--------------+--------------+-------------+----------+\n",
      "|1057724|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1059049|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1133196|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1151194|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1156065|    1|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1311711|    1|           1.0|           0.0|           0.0|          0.0|       1.0|\n",
      "|1396378|    1|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1507765|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1519090|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1528396|    1|           1.0|           1.0|           0.0|          1.0|       1.0|\n",
      "|1537210|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1567623|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1612069|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1617595|    1|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1624220|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1627009|    1|           1.0|           1.0|           0.0|          1.0|       1.0|\n",
      "|1633577|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1770964|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1782257|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "|1796854|    0|           0.0|           0.0|           0.0|          0.0|       0.0|\n",
      "+-------+-----+--------------+--------------+--------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Hybrid Metrics:\n",
      "Accuracy: 0.83\n",
      "F1 Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "def hybrid_function(prediction_GBT, prediction_LGR, prediction_SVM, prediction_rf):\n",
    "    sum_predictions = prediction_GBT + prediction_LGR + prediction_SVM + prediction_rf\n",
    "    if sum_predictions >= 1:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "udf_hybrid_calc_function = F.udf(hybrid_function, DoubleType())\n",
    "results = results.withColumn(\"prediction\",\n",
    "                                 udf_hybrid_calc_function(\n",
    "                                     \"prediction_GBT\",\n",
    "                                     \"prediction_SVC\",\n",
    "                                     \"prediction_LGR\",\n",
    "                                     \"prediction_RF\"))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results, {evaluator.metricName: \"f1\"})\n",
    "results.show()\n",
    "print('Hybrid Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score and the accuracy stayed the same as the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
