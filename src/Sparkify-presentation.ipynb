{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://manavs-mbp.fios-router.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sparkify</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd21e1f4690>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"sparkify\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.json(\"../data/mini_sparkify_event_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data, we will do a vertical show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | Martha Tilston       \n",
      " auth          | Logged In            \n",
      " firstName     | Colin                \n",
      " gender        | M                    \n",
      " itemInSession | 50                   \n",
      " lastName      | Freeman              \n",
      " length        | 277.89016            \n",
      " level         | paid                 \n",
      " location      | Bakersfield, CA      \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1538173362000        \n",
      " sessionId     | 29                   \n",
      " song          | Rockpools            \n",
      " status        | 200                  \n",
      " ts            | 1538352117000        \n",
      " userAgent     | Mozilla/5.0 (Wind... \n",
      " userId        | 30                   \n",
      "-RECORD 1-----------------------------\n",
      " artist        | Five Iron Frenzy     \n",
      " auth          | Logged In            \n",
      " firstName     | Micah                \n",
      " gender        | M                    \n",
      " itemInSession | 79                   \n",
      " lastName      | Long                 \n",
      " length        | 236.09424            \n",
      " level         | free                 \n",
      " location      | Boston-Cambridge-... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1538331630000        \n",
      " sessionId     | 8                    \n",
      " song          | Canada               \n",
      " status        | 200                  \n",
      " ts            | 1538352180000        \n",
      " userAgent     | \"Mozilla/5.0 (Win... \n",
      " userId        | 9                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important column in the data set seems to be the `Page` column. It holds all Sparkify pages that the customers have visited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                page|\n",
      "+--------------------+\n",
      "|              Cancel|\n",
      "|    Submit Downgrade|\n",
      "|         Thumbs Down|\n",
      "|                Home|\n",
      "|           Downgrade|\n",
      "|         Roll Advert|\n",
      "|              Logout|\n",
      "|       Save Settings|\n",
      "|Cancellation Conf...|\n",
      "|               About|\n",
      "| Submit Registration|\n",
      "|            Settings|\n",
      "|               Login|\n",
      "|            Register|\n",
      "|     Add to Playlist|\n",
      "|          Add Friend|\n",
      "|            NextSong|\n",
      "|           Thumbs Up|\n",
      "|                Help|\n",
      "|             Upgrade|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"page\").dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list above we can use the `Cancellation Confirmation` to indicate if a particular user churned or not. We are building a model that predicts if a user is going to churn given the history of interactions with the service.\n",
    "\n",
    "Therfore, it is important to understand the customers that reached the `Cancellation Confirmation` page. These are the customers that churned, and the task is to build a prediction model that can recognize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we indentified our \"goal\", we can let go of some of the columns that are not needed for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | Martha Tilston       \n",
      " auth          | Logged In            \n",
      " gender        | M                    \n",
      " itemInSession | 50                   \n",
      " length        | 277.89016            \n",
      " level         | paid                 \n",
      " location      | Bakersfield, CA      \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1538173362000        \n",
      " sessionId     | 29                   \n",
      " song          | Rockpools            \n",
      " status        | 200                  \n",
      " ts            | 1538352117000        \n",
      " userAgent     | Mozilla/5.0 (Wind... \n",
      " userId        | 30                   \n",
      "-RECORD 1-----------------------------\n",
      " artist        | Five Iron Frenzy     \n",
      " auth          | Logged In            \n",
      " gender        | M                    \n",
      " itemInSession | 79                   \n",
      " length        | 236.09424            \n",
      " level         | free                 \n",
      " location      | Boston-Cambridge-... \n",
      " method        | PUT                  \n",
      " page          | NextSong             \n",
      " registration  | 1538331630000        \n",
      " sessionId     | 8                    \n",
      " song          | Canada               \n",
      " status        | 200                  \n",
      " ts            | 1538352180000        \n",
      " userAgent     | \"Mozilla/5.0 (Win... \n",
      " userId        | 9                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(*['firstName', 'lastName', 'id_copy'])\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are building a model that focuses on a user, remove any null/na values in the userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8346"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter((isnan(data['userId'])) | (data['userId'].isNull()) | (data['userId'] == \"\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(how = 'any', subset = ['userId'])\n",
    "data = data.filter(data[\"userId\"] != \"\") \n",
    "data = data.filter(data['userId'].isNotNull())\n",
    "data.filter((isnan(data['userId'])) | (data['userId'].isNull()) | (data['userId'] == \"\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times in `registration` and `ts` column are given in milliseconds, we will convert those to seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "| registration|           ts|\n",
      "+-------------+-------------+\n",
      "|1.538173362E9|1.538352117E9|\n",
      "| 1.53833163E9| 1.53835218E9|\n",
      "|1.538173362E9|1.538352394E9|\n",
      "| 1.53833163E9|1.538352416E9|\n",
      "|1.538173362E9|1.538352676E9|\n",
      "| 1.53833163E9|1.538352678E9|\n",
      "| 1.53833163E9|1.538352886E9|\n",
      "|1.538173362E9|1.538352899E9|\n",
      "|1.538173362E9|1.538352905E9|\n",
      "|1.538173362E9|1.538353084E9|\n",
      "| 1.53833163E9|1.538353146E9|\n",
      "| 1.53833163E9| 1.53835315E9|\n",
      "|1.538173362E9|1.538353218E9|\n",
      "| 1.53833163E9|1.538353375E9|\n",
      "| 1.53833163E9|1.538353376E9|\n",
      "|1.538173362E9|1.538353441E9|\n",
      "| 1.53833163E9|1.538353576E9|\n",
      "|1.537365219E9|1.538353668E9|\n",
      "|1.538173362E9|1.538353687E9|\n",
      "| 1.53833163E9|1.538353744E9|\n",
      "+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_unit_udf = F.udf(lambda x: float(x/1000), DoubleType())\n",
    "data = data.withColumn(\"registration\", time_unit_udf(\"registration\")). \\\n",
    "    withColumn(\"ts\", time_unit_udf(\"ts\"))\n",
    "\n",
    "data.select('registration', 'ts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above we are deriving the label `churn` as a function of the `Page` column. There are only two values to churn, churned or not churned. Therefore this is going to be a boolean column represented by 1 for churned and 0 for not churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              churn|\n",
      "+-------+-------------------+\n",
      "|  count|                 11|\n",
      "|   mean|0.09090909090909091|\n",
      "| stddev|0.30151134457776363|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cancelation_event_udf = F.udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n",
    "data = data.withColumn(\"churn\", cancelation_event_udf(\"page\"))\n",
    "data.filter(data['userId'] == 125).describe('churn').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that a particular user will have multiple entries, since this is a database of user activities log. A user may have visitied number of other pages before reaching the \"Cancellation\" page. For a user that has churned, we want to make sure that all of his/her logs record 1 for the churn column. For this we will use the Window function from `sql.window`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum as Fsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"userId\") \\\n",
    "        .rangeBetween(Window.unboundedPreceding,\n",
    "                      Window.unboundedFollowing)\n",
    "data = data.withColumn(\"churn\", Fsum(\"churn\").over(window))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|summary|churn|\n",
      "+-------+-----+\n",
      "|  count|   11|\n",
      "|   mean|  1.0|\n",
      "| stddev|  0.0|\n",
      "|    min|    1|\n",
      "|    max|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data['userId'] == 125).describe('churn').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique users we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"userID\").dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total churn instances, again a user has multiple entries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44864"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data['churn'] == 1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a label dataframe that has one entry per each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|label|\n",
      "+------+-----+\n",
      "|100010|    0|\n",
      "|200002|    0|\n",
      "|   125|    1|\n",
      "|   124|    0|\n",
      "|    51|    1|\n",
      "|     7|    0|\n",
      "|    15|    0|\n",
      "|    54|    1|\n",
      "|   155|    0|\n",
      "|100014|    1|\n",
      "|   132|    0|\n",
      "|   154|    0|\n",
      "|   101|    1|\n",
      "|    11|    0|\n",
      "|   138|    0|\n",
      "|300017|    0|\n",
      "|100021|    1|\n",
      "|    29|    1|\n",
      "|    69|    0|\n",
      "|   112|    0|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = data \\\n",
    "    .select('userId', col('churn').alias('label')) \\\n",
    "    .dropDuplicates()\n",
    "label.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users that have been using the service tend to stay with the service, even as a paying customer, than those that recently signed up.\n",
    "\n",
    "Every company selling products and services to customers have an idea of a \"lifetime value\" of a customer. With that in mind we create our first feature.\n",
    "\n",
    "We converted the times to seconds above. After gaining the lifetime of a user, we convert that to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as Fsum, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time since registration\n",
    "time_since_registration = data \\\n",
    "    .select('userId', 'registration', 'ts') \\\n",
    "    .withColumn('lifetime', (data.ts - data.registration)) \\\n",
    "    .groupBy('userId') \\\n",
    "    .agg({'lifetime': 'max'}) \\\n",
    "    .withColumnRenamed('max(lifetime)', 'lifetime') \\\n",
    "    .select('userId', (col('lifetime') / 3600 / 24).alias('lifetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|           lifetime|\n",
      "+-------+-------------------+\n",
      "|  count|                225|\n",
      "|   mean|   79.8456834876543|\n",
      "| stddev|  37.66147001861254|\n",
      "|    min|0.31372685185185184|\n",
      "|    max|  256.3776736111111|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_since_registration.describe('lifetime').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bussiness big and small not only rely on their customers coming back for more good and services, but also referring the bussiness to their friends and family. It is in our nature to refer things that we like. With this idea in mind we will create another feature.\n",
    "\n",
    "Again we will user the \"Page\" column specifically looking for the `Add Friend` page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referring friends\n",
    "referring_friends = data \\\n",
    "    .select('userID', 'page') \\\n",
    "    .where(data.page == 'Add Friend') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'add_friend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        add_friend|\n",
      "+-------+------------------+\n",
      "|  count|               206|\n",
      "|   mean|20.762135922330096|\n",
      "| stddev|20.646779074405007|\n",
      "|    min|                 1|\n",
      "|    max|               143|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "referring_friends.describe('add_friend').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more songs a user listens to, the more likely they are to enjoy the streaming service and keep their subscription. Thus we add a total_songs_listened feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total songs listened\n",
    "total_songs_listened = data \\\n",
    "    .select('userID', 'song') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'total_songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|      total_songs|\n",
      "+-------+-----------------+\n",
      "|  count|              225|\n",
      "|   mean|          1236.24|\n",
      "| stddev|1329.531716432519|\n",
      "|    min|                6|\n",
      "|    max|             9632|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_songs_listened.describe('total_songs').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more songs a user liked on the streaming service, the more it potentially implies that they enjoy their subscription\n",
    "and the value they get from it. They are more likely to keep their subscription if they are liking more songs. Thus we create a feature to count the number of songs a user gives a thumbs_up to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumbs up\n",
    "thumbs_up = data \\\n",
    "    .select('userID', 'page') \\\n",
    "    .where(data.page == 'Thumbs Up') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'num_thumb_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     num_thumb_up|\n",
      "+-------+-----------------+\n",
      "|  count|              220|\n",
      "|   mean|            57.05|\n",
      "| stddev|65.67028650524044|\n",
      "|    min|                1|\n",
      "|    max|              437|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thumbs_up.describe('num_thumb_up').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the more songs a user dislikes, the less likely they are to enjoy their subscription and cancel it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumbs down\n",
    "thumbs_down = data \\\n",
    "    .select('userID', 'page') \\\n",
    "    .where(data.page == 'Thumbs Down') \\\n",
    "    .groupBy('userID') \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'num_thumb_down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    num_thumb_down|\n",
      "+-------+------------------+\n",
      "|  count|               203|\n",
      "|   mean|12.541871921182265|\n",
      "| stddev|13.198108566983787|\n",
      "|    min|                 1|\n",
      "|    max|                75|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thumbs_down.describe('num_thumb_down').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playlist length counts the number of times a user visited the add to playlist page indicating that they added a song to their playlist. A long playlist implies a user is enjoying several songs and wants frequent access to them. This would likely lead to them keeping their subscription. Thus, we create a feature to compute the lenght of the playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playlist length\n",
    "playlist_length = data.select('userID', 'page') \\\n",
    "    .where(data.page == 'Add to Playlist') \\\n",
    "    .groupby('userID').count() \\\n",
    "    .withColumnRenamed('count', 'playlist_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|  playlist_length|\n",
      "+-------+-----------------+\n",
      "|  count|              215|\n",
      "|   mean|30.35348837209302|\n",
      "| stddev| 32.8520568555997|\n",
      "|    min|                1|\n",
      "|    max|              240|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "playlist_length.describe('playlist_length').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg songs per session allows us to measure how long each user session lasts when they open the application and start a session. The longer the session, the more songs the user is listening too. This could imply that the user is enjoying the application and is less likely to cancel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  avg_songs_played per session\n",
    "avg_songs_played = data.where('page == \"NextSong\"') \\\n",
    "    .groupby(['userId', 'sessionId']) \\\n",
    "    .count() \\\n",
    "    .groupby(['userId']) \\\n",
    "    .agg({'count': 'avg'}) \\\n",
    "    .withColumnRenamed('avg(count)', 'avg_songs_played')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| avg_songs_played|\n",
      "+-------+-----------------+\n",
      "|  count|              225|\n",
      "|   mean|70.78971233958933|\n",
      "| stddev| 42.6153697543817|\n",
      "|    min|              3.0|\n",
      "|    max|286.6666666666667|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_songs_played.describe('avg_songs_played').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artist count measures the amount of different artists the user listens to. A user listening to a wide variety of artists could potentially be enjoying the music application more and is likely to keep their subscription. On the other hand, a user listening to only a handful of artists may not be happy with the current subscription and would be likely to churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist count\n",
    "artist_count = data \\\n",
    "    .filter(data.page == \"NextSong\") \\\n",
    "    .select(\"userId\", \"artist\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"artist_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     artist_count|\n",
      "+-------+-----------------+\n",
      "|  count|              225|\n",
      "|   mean|696.3777777777777|\n",
      "| stddev|603.9518698630802|\n",
      "|    min|                3|\n",
      "|    max|             3544|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_count.describe('artist_count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of sessions computes how many times the user has started a session on the app. The more sessions implies more visits to the application meaning they are less likely to churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of sessions\n",
    "num_sessions = data \\\n",
    "    .select(\"userId\", \"sessionId\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'num_sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      num_sessions|\n",
      "+-------+------------------+\n",
      "|  count|               225|\n",
      "|   mean|14.115555555555556|\n",
      "| stddev|14.646884657111562|\n",
      "|    min|                 1|\n",
      "|    max|               107|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_sessions.describe('num_sessions').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Three different models were picked: Gradient Boosting Trees, Logistic Regression and Linear SVC. Results are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"lifetime\",\n",
    "        \"total_songs\",\n",
    "        \"num_thumb_up\",\n",
    "        'num_thumb_down',\n",
    "        'add_friend',\n",
    "        'playlist_length',\n",
    "        'avg_songs_played',\n",
    "        'artist_count',\n",
    "        'num_sessions'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [time_since_registration,\n",
    "                  total_songs_listened,\n",
    "                  thumbs_up,\n",
    "                  thumbs_down,\n",
    "                  referring_friends,\n",
    "                  playlist_length,\n",
    "                  avg_songs_played,\n",
    "                  artist_count,\n",
    "                  num_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------\n",
      " userId           | 100010             \n",
      " num_sessions     | 7                  \n",
      " artist_count     | 252                \n",
      " avg_songs_played | 39.285714285714285 \n",
      " playlist_length  | 7                  \n",
      " add_friend       | 4                  \n",
      " num_thumb_down   | 5                  \n",
      " num_thumb_up     | 17                 \n",
      " total_songs      | 381                \n",
      " lifetime         | 55.6436574074074   \n",
      " label            | 0                  \n",
      "-RECORD 1------------------------------\n",
      " userId           | 200002             \n",
      " num_sessions     | 6                  \n",
      " artist_count     | 339                \n",
      " avg_songs_played | 64.5               \n",
      " playlist_length  | 8                  \n",
      " add_friend       | 4                  \n",
      " num_thumb_down   | 6                  \n",
      " num_thumb_up     | 21                 \n",
      " total_songs      | 474                \n",
      " lifetime         | 70.07462962962963  \n",
      " label            | 0                  \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = features.pop()\n",
    "while len(features) > 0:\n",
    "    data = data.join(features.pop(), 'userID', 'outer')\n",
    "\n",
    "data = data.join(label, 'userID', 'outer').fillna(0)\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- num_sessions: long (nullable = true)\n",
      " |-- artist_count: long (nullable = true)\n",
      " |-- avg_songs_played: double (nullable = false)\n",
      " |-- playlist_length: long (nullable = true)\n",
      " |-- add_friend: long (nullable = true)\n",
      " |-- num_thumb_down: long (nullable = true)\n",
      " |-- num_thumb_up: long (nullable = true)\n",
      " |-- total_songs: long (nullable = true)\n",
      " |-- lifetime: double (nullable = false)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  173|\n",
      "|    1|   52|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector assembler\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"unScaled_features\")\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " userId            | 100010               \n",
      " num_sessions      | 7                    \n",
      " artist_count      | 252                  \n",
      " avg_songs_played  | 39.285714285714285   \n",
      " playlist_length   | 7                    \n",
      " add_friend        | 4                    \n",
      " num_thumb_down    | 5                    \n",
      " num_thumb_up      | 17                   \n",
      " total_songs       | 381                  \n",
      " lifetime          | 55.6436574074074     \n",
      " label             | 0                    \n",
      " unScaled_features | [55.6436574074074... \n",
      "-RECORD 1---------------------------------\n",
      " userId            | 200002               \n",
      " num_sessions      | 6                    \n",
      " artist_count      | 339                  \n",
      " avg_songs_played  | 64.5                 \n",
      " playlist_length   | 8                    \n",
      " add_friend        | 4                    \n",
      " num_thumb_down    | 6                    \n",
      " num_thumb_up      | 21                   \n",
      " total_songs       | 474                  \n",
      " lifetime          | 70.07462962962963    \n",
      " label             | 0                    \n",
      " unScaled_features | [70.0746296296296... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " userID            | 100010               \n",
      " unScaled_features | [55.6436574074074... \n",
      " label             | 0                    \n",
      " features          | [1.47746907860760... \n",
      "-RECORD 1---------------------------------\n",
      " userID            | 200002               \n",
      " unScaled_features | [70.0746296296296... \n",
      " label             | 0                    \n",
      " features          | [1.86064509948757... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.select('userID', 'unScaled_features', 'label')\n",
    "# scale the features\n",
    "scaler = StandardScaler(inputCol=\"unScaled_features\", outputCol=\"features\", withStd=True)\n",
    "scalerModel = scaler.fit(data)\n",
    "data = scalerModel.transform(data)\n",
    "data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "trainTest = data.randomSplit([0.8, 0.2])\n",
    "trainingDF = trainTest[0]\n",
    "testDF = trainTest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier, LogisticRegression, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+\n",
      "|userID|label|prediction|\n",
      "+------+-----+----------+\n",
      "|    51|    1|       1.0|\n",
      "|     7|    0|       0.0|\n",
      "|    69|    0|       0.0|\n",
      "|     3|    1|       0.0|\n",
      "|    30|    0|       0.0|\n",
      "|    22|    0|       0.0|\n",
      "|100022|    1|       0.0|\n",
      "|    35|    0|       0.0|\n",
      "|    52|    0|       0.0|\n",
      "|    47|    0|       0.0|\n",
      "+------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Gradient Boosted Trees Metrics:\n",
      "Accuracy: 0.78\n",
      "F1 Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Trees\n",
    "\n",
    "# initialize classifier\n",
    "GradBoostTree = GBTClassifier()\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "depth = [3, 5, 7] \n",
    "iterations = [10, 20, 30]\n",
    "bins = [16, 32, 64]\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(GradBoostTree.maxDepth, depth) \\\n",
    "    .addGrid(GradBoostTree.maxIter, iterations) \\\n",
    "    .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "cross_validator = CrossValidator(estimator=GradBoostTree,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=evaluator,\n",
    "                                 numFolds=3)\n",
    "\n",
    "# Fit the model\n",
    "cvModel_GradBoostTree = GradBoostTree.fit(trainingDF) ## --> CHANGE THIS BACK TO cross_validator to run it\n",
    "\n",
    "# Make Predictions\n",
    "results_GradBoostTree = cvModel_GradBoostTree.transform(testDF)\n",
    "results_GradBoostTree = results_GradBoostTree.select('userID', 'label', 'prediction')\n",
    "results_GradBoostTree.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_GradBoostTree, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_GradBoostTree, {evaluator.metricName: \"f1\"})\n",
    "print('Gradient Boosted Trees Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+\n",
      "|userID|label|prediction|\n",
      "+------+-----+----------+\n",
      "|    51|    1|       0.0|\n",
      "|     7|    0|       0.0|\n",
      "|    69|    0|       0.0|\n",
      "|     3|    1|       0.0|\n",
      "|    30|    0|       0.0|\n",
      "|    22|    0|       0.0|\n",
      "|100022|    1|       1.0|\n",
      "|    35|    0|       0.0|\n",
      "|    52|    0|       0.0|\n",
      "|    47|    0|       0.0|\n",
      "+------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.85\n",
      "F1 Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "\n",
    "# initialize classifier\n",
    "maxIter = 10\n",
    "lgr = LogisticRegression(maxIter=maxIter)\n",
    "\n",
    "# Fit the model\n",
    "cvModel_lgr = lgr.fit(trainingDF)\n",
    "\n",
    "# Make Predictions\n",
    "results_lgr = cvModel_lgr.transform(testDF).select('userID', 'label', 'prediction')\n",
    "results_lgr.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_lgr, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_lgr, {evaluator.metricName: \"f1\"})\n",
    "print('Logistic Regression Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+\n",
      "|userID|label|prediction|\n",
      "+------+-----+----------+\n",
      "|    51|    1|       0.0|\n",
      "|     7|    0|       0.0|\n",
      "|    69|    0|       0.0|\n",
      "|     3|    1|       0.0|\n",
      "|    30|    0|       0.0|\n",
      "|    22|    0|       0.0|\n",
      "|100022|    1|       0.0|\n",
      "|    35|    0|       0.0|\n",
      "|    52|    0|       0.0|\n",
      "|    47|    0|       0.0|\n",
      "+------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.80\n",
      "F1 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "# initialize classifier\n",
    "maxIter = 10\n",
    "svc = LinearSVC(maxIter=maxIter)\n",
    "\n",
    "# Fit the model\n",
    "cvModel_svc = svc.fit(trainingDF)\n",
    "\n",
    "# Make Predictions\n",
    "results_svc = cvModel_svc.transform(testDF).select('userID', 'label', 'prediction')\n",
    "results_svc.show(10)\n",
    "\n",
    "# Get Results\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(results_svc, {evaluator.metricName: \"accuracy\"})\n",
    "f1Score = evaluator.evaluate(results_svc, {evaluator.metricName: \"f1\"})\n",
    "print('Logistic Regression Metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 Score: {:.2f}'.format(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
